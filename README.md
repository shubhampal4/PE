# Kubernetes, Observability, and Airflow Architecture Task Bundle

## ğŸ“ Overview

This repository contains manifests and code snippets for mastering:
- Kubernetes Pod scheduling and network policies
- OpenTelemetry-based observability and tracing in Python
- Prometheus SLO-based alerting strategy
- Apache Airflow DAG design and debugging

---

## ğŸš€ 1. Kubernetes Mastery

### 1.1 Pod Scheduling & Resource Management

âœ… **Objective**:  
Create a pod that:
- Runs only on `env=prod` nodes with GPU
- Has resource requests and limits (500Mi/250m â†’ 2Gi/1CPU)
- Is not evicted under memory pressure
- Mounts a secret volume

ğŸ“„ **File**: `k8s/pod_gpu.yaml`

### 1.2 Network Policy & Secure Exposure

âœ… **Objective**:  
Deploy a frontend app exposed via Ingress, and restrict access to it using a `NetworkPolicy` that only allows pods with label `access: true` from the `backend` namespace.

ğŸ“„ **Files**:
- `k8s/frontend_ingress.yaml`
- `k8s/network_policy.yaml`

---

## ğŸ” 2. Observability & Tracing

### 2.1 OpenTelemetry Instrumentation in Python

âœ… **Objective**:  
Instrument a Python function to:
- Create a span inside `process_payment(user_id)`
- Add baggage and attributes
- Export trace data to local OpenTelemetry Collector (OTLP)

ğŸ“„ **File**: `observability/opentelemetry_payment.py`  
â¡ï¸ Uses: `OTLPSpanExporter`, `BatchSpanProcessor`, and `baggage`.

### 2.2 SLOs & Alert Design

âœ… **Objective**:  
Design Prometheus alerts for an API endpoint `/checkout` with:
- 2 SLIs: latency and error rate
- Corresponding SLO targets
- A multi-window burn rate alert

ğŸ“„ **File**: `observability/slo_alerts.yaml`

---

## âš™ï¸ 3. Airflow Architecture & DAG Design

### 3.1 DAG: Extract â†’ Transform â†’ Load to S3

âœ… **Objective**:  
Create a DAG that:
- Extracts data from an API
- Transforms data
- Loads to AWS S3
- Retries with exponential backoff

ğŸ“„ **File**: `airflow/api_to_s3_dag.py`  
â¡ï¸ Uses `@task`, `boto3`, `requests`, and DAG structuring best practices.

### 3.2 DAG Debugging Scenario

âœ… **Problem**:  
â€œA task is skipped randomly despite the previous one succeeding.â€

ğŸ›  **Explanation**:
- Might be due to improper `trigger_rule` (default: `all_success`)
- Use `TriggerRule.ALL_DONE` to ensure task always runs

ğŸ“„ **File**: `airflow/debugging_notes.md`

---

## ğŸ“¦ Folder Structure

project-root/
â”œâ”€â”€ k8s/
â”‚ â”œâ”€â”€ pod_gpu.yaml
â”‚ â”œâ”€â”€ frontend_ingress.yaml
â”‚ â””â”€â”€ networkpolicy.yaml
â”œâ”€â”€ observability/
â”‚ â”œâ”€â”€ opentelemetry_payment.py
â”‚ â””â”€â”€ slo_alerts.yaml
â”œâ”€â”€ airflow/
â”‚ â”œâ”€â”€ api_to_s3_dag.py
â”‚ â””â”€â”€ debugging_notes.md
â””â”€â”€ README.md â† This file